import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin, urlparse

# 1. è®¾ç½®ç›®æ ‡ç½‘é¡µ URL
url = "http://localhost:8086/orgs/c9f43c6f5ac7c31c"  # æ›¿æ¢ä¸ºä½ æƒ³çˆ¬çš„ç½‘é¡µ

# 2. è®¾ç½®è¯·æ±‚å¤´ï¼ˆä¼ªè£…æˆæµè§ˆå™¨ï¼Œé¿å…è¢«åçˆ¬ï¼‰
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# 3. å‘é€è¯·æ±‚è·å–ç½‘é¡µå†…å®¹
try:
    response = requests.get(url, headers=headers)
    response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
    response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç 
except requests.RequestException as e:
    print(f"è¯·æ±‚å¤±è´¥: {e}")
    exit()

# 4. è§£æ HTML
soup = BeautifulSoup(response.text, 'html.parser')

# 5. æ‰¾å‡ºæ‰€æœ‰ <img> æ ‡ç­¾
img_tags = soup.find_all('img')

# 6. åˆ›å»ºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹
os.makedirs('downloaded_images', exist_ok=True)

# 7. æå–å¹¶ä¸‹è½½å›¾ç‰‡
for idx, img in enumerate(img_tags):
    # è·å–å›¾ç‰‡é“¾æ¥ï¼ˆä¼˜å…ˆ srcï¼Œè€ƒè™‘ data-src ç­‰æ‡’åŠ è½½ï¼‰
    img_url = img.get('src') or img.get('data-src') or img.get('data-original')
    if not img_url:
        continue  # è·³è¿‡æ²¡æœ‰ src çš„å›¾ç‰‡

    # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼Œè½¬ä¸ºç»å¯¹ URL
    img_url = urljoin(url, img_url)

    # è·å–æ–‡ä»¶åï¼ˆä» URL ä¸­æå–ï¼‰
    parsed_url = urlparse(img_url)
    filename = os.path.basename(parsed_url.path)
    if not filename or '.' not in filename:
        filename = f"image_{idx}.jpg"  # é»˜è®¤å‘½å

    filepath = os.path.join('downloaded_images', filename)

    # ä¸‹è½½å›¾ç‰‡
    try:
        img_data = requests.get(img_url, headers=headers, timeout=10)
        img_data.raise_for_status()

        # ä¿å­˜å›¾ç‰‡
        with open(filepath, 'wb') as f:
            f.write(img_data.content)
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} <- {img_url}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} ({e})")

print("ğŸ‰ å›¾ç‰‡çˆ¬å–å®Œæˆï¼")